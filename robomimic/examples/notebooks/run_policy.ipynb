{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b15f2e",
   "metadata": {},
   "source": [
    "# Run a trained policy\n",
    "\n",
    "This notebook will provide examples on how to run a trained policy and visualize the rollout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000a4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deniz/miniforge3/envs/robodiff/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "from robomimic.envs.env_base import EnvBase\n",
    "from robomimic.algo import RolloutPolicy\n",
    "\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47427159",
   "metadata": {},
   "source": [
    "### Download policy checkpoint\n",
    "First, let's try downloading a pretrained model from our model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfdfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained checkpooint from the model zoo\n",
    "\n",
    "ckpt_path = \"lift_ph_low_dim_epoch_1000_succ_100.pth\"\n",
    "# Lift (Proficient Human)\n",
    "urllib.request.urlretrieve(\n",
    "    \"http://downloads.cs.stanford.edu/downloads/rt_benchmark/model_zoo/lift/bc_rnn/lift_ph_low_dim_epoch_1000_succ_100.pth\",\n",
    "    filename=ckpt_path\n",
    ")\n",
    "\n",
    "assert os.path.exists(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d2e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"latest.ckpt\"\n",
    "assert os.path.exists(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c25c6",
   "metadata": {},
   "source": [
    "### Loading trained policy\n",
    "We have a convenient function called `policy_from_checkpoint` that takes care of building the correct model from the checkpoint and load the trained weights. Of course you could also load the checkpoint manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf84aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Loaded Config =============\n",
      "{\n",
      "    \"algo_name\": \"bc\",\n",
      "    \"experiment\": {\n",
      "        \"name\": \"core_bc_rnn_lift_ph_low_dim\",\n",
      "        \"validate\": true,\n",
      "        \"logging\": {\n",
      "            \"terminal_output_to_txt\": true,\n",
      "            \"log_tb\": true\n",
      "        },\n",
      "        \"save\": {\n",
      "            \"enabled\": true,\n",
      "            \"every_n_seconds\": null,\n",
      "            \"every_n_epochs\": 50,\n",
      "            \"epochs\": [],\n",
      "            \"on_best_validation\": false,\n",
      "            \"on_best_rollout_return\": false,\n",
      "            \"on_best_rollout_success_rate\": true\n",
      "        },\n",
      "        \"epoch_every_n_steps\": 100,\n",
      "        \"validation_epoch_every_n_steps\": 10,\n",
      "        \"env\": null,\n",
      "        \"additional_envs\": null,\n",
      "        \"render\": false,\n",
      "        \"render_video\": true,\n",
      "        \"keep_all_videos\": false,\n",
      "        \"video_skip\": 5,\n",
      "        \"rollout\": {\n",
      "            \"enabled\": true,\n",
      "            \"n\": 50,\n",
      "            \"horizon\": 400,\n",
      "            \"rate\": 50,\n",
      "            \"warmstart\": 0,\n",
      "            \"terminate_on_success\": true\n",
      "        }\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"data\": \"/cvgl2/u/amandlek/batch_datasets/final_benchmark_datasets/lift/ph/low_dim.hdf5\",\n",
      "        \"output_dir\": \"/cvgl2/u/amandlek/batch_datasets/verification_run_results/core/bc_rnn/lift/ph/low_dim/trained_models\",\n",
      "        \"num_data_workers\": 0,\n",
      "        \"hdf5_cache_mode\": \"all\",\n",
      "        \"hdf5_use_swmr\": true,\n",
      "        \"hdf5_normalize_obs\": false,\n",
      "        \"hdf5_filter_key\": null,\n",
      "        \"seq_length\": 10,\n",
      "        \"dataset_keys\": [\n",
      "            \"actions\",\n",
      "            \"rewards\",\n",
      "            \"dones\"\n",
      "        ],\n",
      "        \"goal_mode\": null,\n",
      "        \"cuda\": true,\n",
      "        \"batch_size\": 100,\n",
      "        \"num_epochs\": 2000,\n",
      "        \"seed\": 1\n",
      "    },\n",
      "    \"algo\": {\n",
      "        \"optim_params\": {\n",
      "            \"policy\": {\n",
      "                \"learning_rate\": {\n",
      "                    \"initial\": 0.0001,\n",
      "                    \"decay_factor\": 0.1,\n",
      "                    \"epoch_schedule\": []\n",
      "                },\n",
      "                \"regularization\": {\n",
      "                    \"L2\": 0.0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"loss\": {\n",
      "            \"l2_weight\": 1.0,\n",
      "            \"l1_weight\": 0.0,\n",
      "            \"cos_weight\": 0.0\n",
      "        },\n",
      "        \"actor_layer_dims\": [],\n",
      "        \"gaussian\": {\n",
      "            \"enabled\": false,\n",
      "            \"fixed_std\": false,\n",
      "            \"init_std\": 0.1,\n",
      "            \"min_std\": 0.01,\n",
      "            \"std_activation\": \"softplus\",\n",
      "            \"low_noise_eval\": true\n",
      "        },\n",
      "        \"gmm\": {\n",
      "            \"enabled\": true,\n",
      "            \"num_modes\": 5,\n",
      "            \"min_std\": 0.0001,\n",
      "            \"std_activation\": \"softplus\",\n",
      "            \"low_noise_eval\": true\n",
      "        },\n",
      "        \"vae\": {\n",
      "            \"enabled\": false,\n",
      "            \"latent_dim\": 14,\n",
      "            \"latent_clip\": null,\n",
      "            \"kl_weight\": 1.0,\n",
      "            \"decoder\": {\n",
      "                \"is_conditioned\": true,\n",
      "                \"reconstruction_sum_across_elements\": false\n",
      "            },\n",
      "            \"prior\": {\n",
      "                \"learn\": false,\n",
      "                \"is_conditioned\": false,\n",
      "                \"use_gmm\": false,\n",
      "                \"gmm_num_modes\": 10,\n",
      "                \"gmm_learn_weights\": false,\n",
      "                \"use_categorical\": false,\n",
      "                \"categorical_dim\": 10,\n",
      "                \"categorical_gumbel_softmax_hard\": false,\n",
      "                \"categorical_init_temp\": 1.0,\n",
      "                \"categorical_temp_anneal_step\": 0.001,\n",
      "                \"categorical_min_temp\": 0.3\n",
      "            },\n",
      "            \"encoder_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ],\n",
      "            \"decoder_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ],\n",
      "            \"prior_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ]\n",
      "        },\n",
      "        \"rnn\": {\n",
      "            \"enabled\": true,\n",
      "            \"horizon\": 10,\n",
      "            \"hidden_dim\": 400,\n",
      "            \"rnn_type\": \"LSTM\",\n",
      "            \"num_layers\": 2,\n",
      "            \"open_loop\": false,\n",
      "            \"kwargs\": {\n",
      "                \"bidirectional\": false\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"observation\": {\n",
      "        \"modalities\": {\n",
      "            \"obs\": {\n",
      "                \"low_dim\": [\n",
      "                    \"robot0_eef_pos\",\n",
      "                    \"robot0_eef_quat\",\n",
      "                    \"robot0_gripper_qpos\",\n",
      "                    \"object\"\n",
      "                ],\n",
      "                \"rgb\": []\n",
      "            },\n",
      "            \"goal\": {\n",
      "                \"low_dim\": [],\n",
      "                \"rgb\": []\n",
      "            }\n",
      "        },\n",
      "        \"encoder\": {\n",
      "            \"rgb\": {\n",
      "                \"core_class\": \"VisualCore\",\n",
      "                \"core_kwargs\": {\n",
      "                    \"backbone_kwargs\": {\n",
      "                        \"pretrained\": false,\n",
      "                        \"input_coord_conv\": false\n",
      "                    },\n",
      "                    \"pool_kwargs\": {\n",
      "                        \"num_kp\": 32,\n",
      "                        \"learnable_temperature\": false,\n",
      "                        \"temperature\": 1.0,\n",
      "                        \"noise_std\": 0.0\n",
      "                    },\n",
      "                    \"feature_dimension\": 64,\n",
      "                    \"backbone_class\": \"ResNet18Conv\",\n",
      "                    \"pool_class\": \"SpatialSoftmax\"\n",
      "                },\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {\n",
      "                    \"crop_height\": 76,\n",
      "                    \"crop_width\": 76,\n",
      "                    \"num_crops\": 1,\n",
      "                    \"pos_enc\": false\n",
      "                }\n",
      "            },\n",
      "            \"low_dim\": {\n",
      "                \"core_class\": null,\n",
      "                \"core_kwargs\": {\n",
      "                    \"backbone_kwargs\": {},\n",
      "                    \"pool_kwargs\": {}\n",
      "                },\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_eef_pos', 'object']\n",
      "using obs modality: rgb with keys: []\n",
      "============= Loaded Policy =============\n",
      "ObservationKeyToModalityDict: mean not found, adding mean to mapping with assumed low_dim modality!\n",
      "ObservationKeyToModalityDict: scale not found, adding scale to mapping with assumed low_dim modality!\n",
      "ObservationKeyToModalityDict: logits not found, adding logits to mapping with assumed low_dim modality!\n",
      "BC_RNN_GMM (\n",
      "  ModuleDict(\n",
      "    (policy): RNNGMMActorNetwork(\n",
      "        action_dim=7, std_activation=softplus, low_noise_eval=True, num_nodes=5, min_std=0.0001\n",
      "  \n",
      "        encoder=ObservationGroupEncoder(\n",
      "            group=obs\n",
      "            ObservationEncoder(\n",
      "                Key(\n",
      "                    name=object\n",
      "                    shape=(10,)\n",
      "                    modality=low_dim\n",
      "                    randomizer=None\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=robot0_eef_pos\n",
      "                    shape=(3,)\n",
      "                    modality=low_dim\n",
      "                    randomizer=None\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=robot0_eef_quat\n",
      "                    shape=(4,)\n",
      "                    modality=low_dim\n",
      "                    randomizer=None\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=robot0_gripper_qpos\n",
      "                    shape=(2,)\n",
      "                    modality=low_dim\n",
      "                    randomizer=None\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                output_shape=[19]\n",
      "            )\n",
      "        )\n",
      "  \n",
      "        rnn=RNN_Base(\n",
      "          (per_step_net): ObservationDecoder(\n",
      "              Key(\n",
      "                  name=mean\n",
      "                  shape=(5, 7)\n",
      "                  modality=low_dim\n",
      "                  net=(Linear(in_features=400, out_features=35, bias=True))\n",
      "              )\n",
      "              Key(\n",
      "                  name=scale\n",
      "                  shape=(5, 7)\n",
      "                  modality=low_dim\n",
      "                  net=(Linear(in_features=400, out_features=35, bias=True))\n",
      "              )\n",
      "              Key(\n",
      "                  name=logits\n",
      "                  shape=(5,)\n",
      "                  modality=low_dim\n",
      "                  net=(Linear(in_features=400, out_features=5, bias=True))\n",
      "              )\n",
      "          )\n",
      "          (nets): LSTM(19, 400, num_layers=2, batch_first=True)\n",
      "        )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = TorchUtils.get_torch_device(try_to_use_cuda=True)\n",
    "\n",
    "# restore policy\n",
    "policy, ckpt_dict = FileUtils.policy_from_checkpoint(ckpt_path=ckpt_path, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872a3f0",
   "metadata": {},
   "source": [
    "### Creating rollout envionment\n",
    "The policy checkpoint also contains sufficient information to recreate the environment that it's trained with. Again, you may manually create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d00c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 GPUs for rendering. Using device 0.\n",
      "Created environment with name Lift\n",
      "Action size is 7\n",
      "============= Loaded Environment =============\n",
      "Lift\n",
      "{\n",
      "    \"camera_depths\": false,\n",
      "    \"camera_heights\": 84,\n",
      "    \"camera_widths\": 84,\n",
      "    \"control_freq\": 20,\n",
      "    \"controller_configs\": {\n",
      "        \"control_delta\": true,\n",
      "        \"damping\": 1,\n",
      "        \"damping_limits\": [\n",
      "            0,\n",
      "            10\n",
      "        ],\n",
      "        \"impedance_mode\": \"fixed\",\n",
      "        \"input_max\": 1,\n",
      "        \"input_min\": -1,\n",
      "        \"interpolation\": null,\n",
      "        \"kp\": 150,\n",
      "        \"kp_limits\": [\n",
      "            0,\n",
      "            300\n",
      "        ],\n",
      "        \"orientation_limits\": null,\n",
      "        \"output_max\": [\n",
      "            0.05,\n",
      "            0.05,\n",
      "            0.05,\n",
      "            0.5,\n",
      "            0.5,\n",
      "            0.5\n",
      "        ],\n",
      "        \"output_min\": [\n",
      "            -0.05,\n",
      "            -0.05,\n",
      "            -0.05,\n",
      "            -0.5,\n",
      "            -0.5,\n",
      "            -0.5\n",
      "        ],\n",
      "        \"position_limits\": null,\n",
      "        \"ramp_ratio\": 0.2,\n",
      "        \"type\": \"OSC_POSE\",\n",
      "        \"uncouple_pos_ori\": true\n",
      "    },\n",
      "    \"has_offscreen_renderer\": true,\n",
      "    \"has_renderer\": false,\n",
      "    \"ignore_done\": true,\n",
      "    \"render_gpu_device_id\": 0,\n",
      "    \"reward_shaping\": false,\n",
      "    \"robots\": [\n",
      "        \"Panda\"\n",
      "    ],\n",
      "    \"use_camera_obs\": false,\n",
      "    \"use_object_obs\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# create environment from saved checkpoint\n",
    "env, _ = FileUtils.env_from_checkpoint(\n",
    "    ckpt_dict=ckpt_dict, \n",
    "    render=False, # we won't do on-screen rendering in the notebook\n",
    "    render_offscreen=True, # render to RGB images for video\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac0e9f",
   "metadata": {},
   "source": [
    "### Define the rollout loop\n",
    "Now let's define the main rollout loop. The loop runs the policy to a target `horizon` and optionally writes the rollout to a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd1375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(policy, env, horizon, render=False, video_writer=None, video_skip=5, camera_names=None):\n",
    "    \"\"\"\n",
    "    Helper function to carry out rollouts. Supports on-screen rendering, off-screen rendering to a video, \n",
    "    and returns the rollout trajectory.\n",
    "    Args:\n",
    "        policy (instance of RolloutPolicy): policy loaded from a checkpoint\n",
    "        env (instance of EnvBase): env loaded from a checkpoint or demonstration metadata\n",
    "        horizon (int): maximum horizon for the rollout\n",
    "        render (bool): whether to render rollout on-screen\n",
    "        video_writer (imageio writer): if provided, use to write rollout to video\n",
    "        video_skip (int): how often to write video frames\n",
    "        camera_names (list): determines which camera(s) are used for rendering. Pass more than\n",
    "            one to output a video with multiple camera views concatenated horizontally.\n",
    "    Returns:\n",
    "        stats (dict): some statistics for the rollout - such as return, horizon, and task success\n",
    "    \"\"\"\n",
    "    assert isinstance(env, EnvBase)\n",
    "    assert isinstance(policy, RolloutPolicy)\n",
    "    assert not (render and (video_writer is not None))\n",
    "\n",
    "    policy.start_episode()\n",
    "    obs = env.reset()\n",
    "    state_dict = env.get_state()\n",
    "\n",
    "    # hack that is necessary for robosuite tasks for deterministic action playback\n",
    "    obs = env.reset_to(state_dict)\n",
    "\n",
    "    results = {}\n",
    "    video_count = 0  # video frame counter\n",
    "    total_reward = 0.\n",
    "    try:\n",
    "        for step_i in range(horizon):\n",
    "\n",
    "            # get action from policy\n",
    "            act = policy(ob=obs)\n",
    "            print(f\" action:\", act)\n",
    "            print(f\" action shape:\", act.shape)\n",
    "\n",
    "            # play action\n",
    "            next_obs, r, done, _ = env.step(act)\n",
    "\n",
    "            # compute reward\n",
    "            total_reward += r\n",
    "            success = env.is_success()[\"task\"]\n",
    "\n",
    "            # visualization\n",
    "            if render:\n",
    "                env.render(mode=\"human\", camera_name=camera_names[0])\n",
    "            if video_writer is not None:\n",
    "                if video_count % video_skip == 0:\n",
    "                    video_img = []\n",
    "                    for cam_name in camera_names:\n",
    "                        video_img.append(env.render(mode=\"rgb_array\", height=512, width=512, camera_name=cam_name))\n",
    "                    video_img = np.concatenate(video_img, axis=1) # concatenate horizontally\n",
    "                    video_writer.append_data(video_img)\n",
    "                video_count += 1\n",
    "\n",
    "            # break if done or if success\n",
    "            if done or success:\n",
    "                break\n",
    "\n",
    "            # update for next iter\n",
    "            obs = deepcopy(next_obs)\n",
    "            state_dict = env.get_state()\n",
    "\n",
    "    except env.rollout_exceptions as e:\n",
    "        print(\"WARNING: got rollout exception {}\".format(e))\n",
    "\n",
    "    stats = dict(Return=total_reward, Horizon=(step_i + 1), Success_Rate=float(success))\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43d371",
   "metadata": {},
   "source": [
    "### Run the policy\n",
    "Now let's rollout the policy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6e1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_horizon = 400\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "video_path = \"rollout_lift.mp4\"\n",
    "video_writer = imageio.get_writer(video_path, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa67efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " action: [ 0.18479872 -0.02011254 -0.02240157  0.00597613  0.11409268 -0.0901163\n",
      " -1.0000532 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.41578174  0.03356503 -0.26325935  0.03874867  0.10183106  0.02100793\n",
      " -1.0000445 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.5538636   0.09370813 -0.25068793  0.03063447  0.07590405 -0.03996489\n",
      " -1.000195  ]\n",
      " action shape: (7,)\n",
      " action: [ 0.5783088   0.05156371 -0.28671     0.02922499  0.07496982 -0.00352242\n",
      " -0.99983376]\n",
      " action shape: (7,)\n",
      " action: [ 0.59841377  0.02070552 -0.37664035  0.00249829  0.03586506 -0.02232838\n",
      " -1.0002284 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.5980622   0.00903671 -0.39929843 -0.01099908  0.00854111 -0.04194811\n",
      " -0.9999039 ]\n",
      " action shape: (7,)\n",
      " action: [ 5.81596792e-01 -2.63150345e-04 -3.52592587e-01 -1.11483615e-02\n",
      " -8.57607592e-05 -4.33988087e-02 -9.99844849e-01]\n",
      " action shape: (7,)\n",
      " action: [ 0.5628438  -0.01294432 -0.2995015  -0.00746667 -0.00183164 -0.03363452\n",
      " -0.9999792 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.5483652  -0.02680757 -0.26058543 -0.00392566 -0.00226814 -0.02403781\n",
      " -0.9999313 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.5380963  -0.03813161 -0.22507356 -0.0017288  -0.00146508 -0.02264761\n",
      " -1.0000978 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.54601264  0.03261162 -0.54491806 -0.01155297  0.00276353 -0.14077058\n",
      " -1.0000806 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.4775519  -0.02209713 -0.5023603  -0.0175023  -0.00696774 -0.1248187\n",
      " -1.0002198 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.48659757  0.01507436 -0.421411   -0.00520595 -0.0171451  -0.0891439\n",
      " -1.000066  ]\n",
      " action shape: (7,)\n",
      " action: [ 0.47384673  0.00327925 -0.43959114  0.00336187 -0.02334977 -0.09123809\n",
      " -1.0000954 ]\n",
      " action shape: (7,)\n",
      " action: [ 4.3205237e-01 -3.2221902e-02 -4.6786222e-01 -6.0397735e-05\n",
      " -3.1045353e-02 -9.0240091e-02 -9.9999595e-01]\n",
      " action shape: (7,)\n",
      " action: [ 0.38121367 -0.06717912 -0.47772405 -0.0059346  -0.03433231 -0.09862468\n",
      " -1.0000238 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.33213112 -0.09560255 -0.48505118 -0.01175149 -0.04165812 -0.10710837\n",
      " -0.9999703 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.29645184 -0.12089083 -0.48778462 -0.01962337 -0.05677103 -0.10751602\n",
      " -0.99991137]\n",
      " action shape: (7,)\n",
      " action: [ 0.2691234  -0.13762854 -0.48161373 -0.02580697 -0.07312144 -0.09998571\n",
      " -1.000102  ]\n",
      " action shape: (7,)\n",
      " action: [ 0.23719956 -0.13726877 -0.47040907 -0.02659764 -0.08550648 -0.08928424\n",
      " -1.0000067 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.198355   -0.06890546 -0.42884424 -0.00868813 -0.05205293 -0.09231757\n",
      " -0.9999595 ]\n",
      " action shape: (7,)\n",
      " action: [ 1.8062289e-01 -5.5552170e-02 -4.6241340e-01  9.2309085e-04\n",
      " -7.4102186e-02 -8.9658543e-02 -1.0000180e+00]\n",
      " action shape: (7,)\n",
      " action: [ 1.8107496e-01 -6.2843472e-02 -4.0159678e-01 -4.0735086e-04\n",
      " -8.5126303e-02 -7.6251850e-02 -9.9990076e-01]\n",
      " action shape: (7,)\n",
      " action: [ 0.131842   -0.05699215 -0.35923347 -0.00932769 -0.07879169 -0.0912491\n",
      " -0.99992245]\n",
      " action shape: (7,)\n",
      " action: [ 0.11504169 -0.0368193  -0.2889834  -0.01035108 -0.07306949 -0.09629152\n",
      " -1.0000658 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.11391515 -0.0267602  -0.22961943 -0.01248319 -0.06932296 -0.08483513\n",
      " -0.99993855]\n",
      " action shape: (7,)\n",
      " action: [ 0.10124301 -0.01596087 -0.20908646 -0.01375988 -0.06539584 -0.06866989\n",
      " -1.0000697 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.06976476 -0.00340104 -0.21745558 -0.01270873 -0.06012277 -0.05371843\n",
      " -0.99989474]\n",
      " action shape: (7,)\n",
      " action: [ 0.04809639 -0.00211944 -0.2198695  -0.00966017 -0.05398394 -0.04488367\n",
      " -1.000008  ]\n",
      " action shape: (7,)\n",
      " action: [ 0.04307779 -0.01774161 -0.22309427 -0.00726662 -0.05142474 -0.03612544\n",
      " -0.9999951 ]\n",
      " action shape: (7,)\n",
      " action: [-0.01278877 -0.05213081 -0.31229553  0.00677353 -0.07458837 -0.04441701\n",
      " -0.9999968 ]\n",
      " action shape: (7,)\n",
      " action: [-0.02539564 -0.04112723 -0.32018766  0.01007755 -0.0922536  -0.02087121\n",
      " -0.99997556]\n",
      " action shape: (7,)\n",
      " action: [-0.03958383 -0.03922138 -0.36240402  0.01313093 -0.08621886 -0.02938688\n",
      " -0.99991924]\n",
      " action shape: (7,)\n",
      " action: [-0.07461888 -0.06051728 -0.382764    0.00978801 -0.07862084 -0.03885709\n",
      " -0.999988  ]\n",
      " action shape: (7,)\n",
      " action: [-0.07368774 -0.07017285 -0.36236846  0.00709848 -0.07482629 -0.03957033\n",
      " -1.0000733 ]\n",
      " action shape: (7,)\n",
      " action: [-0.04313477 -0.09580028 -0.3243775   0.00793149 -0.0694491  -0.03309889\n",
      " -1.0000204 ]\n",
      " action shape: (7,)\n",
      " action: [-0.02493627 -0.1257835  -0.30085802  0.01380693 -0.06546348 -0.02718044\n",
      " -0.99999136]\n",
      " action shape: (7,)\n",
      " action: [-0.02308028 -0.1526399  -0.29261732  0.02179468 -0.06304818 -0.02136171\n",
      " -1.0001227 ]\n",
      " action shape: (7,)\n",
      " action: [-0.04499458 -0.12124912 -0.39502963  0.01042643 -0.04885941 -0.01555791\n",
      "  1.0000738 ]\n",
      " action shape: (7,)\n",
      " action: [-0.03018411 -0.12156675 -0.3457876   0.01158936 -0.03963545 -0.01123331\n",
      "  0.99997586]\n",
      " action shape: (7,)\n",
      " action: [ 0.00357444 -0.0144633   0.05387454  0.03670119 -0.02042088  0.00563423\n",
      "  0.9999026 ]\n",
      " action shape: (7,)\n",
      " action: [-0.01783262  0.02864863  0.04823019  0.06586788 -0.03023057  0.01295278\n",
      "  1.000009  ]\n",
      " action shape: (7,)\n",
      " action: [ 1.1604341e-02  1.0907317e-02  7.6265402e-02  7.7756956e-02\n",
      " -7.8904565e-04  8.9869434e-03  9.9999541e-01]\n",
      " action shape: (7,)\n",
      " action: [-0.00891542  0.04854184 -0.17121257  0.0684212   0.01482944 -0.00574396\n",
      "  0.9999112 ]\n",
      " action shape: (7,)\n",
      " action: [-0.0160547   0.05902374 -0.27787012  0.05319553  0.02383033 -0.01617467\n",
      "  1.0000674 ]\n",
      " action shape: (7,)\n",
      " action: [-0.01200511  0.04772433 -0.22725098  0.03581244  0.0349484  -0.01875845\n",
      "  0.99993247]\n",
      " action shape: (7,)\n",
      " action: [-0.00606954  0.02603768 -0.06307669  0.02125093  0.04811165 -0.01609388\n",
      "  1.0001304 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.01374154  0.00178102  0.2170879   0.00907921  0.05837635 -0.01160801\n",
      "  1.0000863 ]\n",
      " action shape: (7,)\n",
      " action: [ 0.02270539 -0.02489033  0.45916006  0.00153318  0.0660377  -0.0068252\n",
      "  1.0001581 ]\n",
      " action shape: (7,)\n",
      " action: [ 1.8831285e-02 -4.3722719e-02  5.8540636e-01 -6.3716201e-04\n",
      "  7.1498409e-02 -2.3052264e-03  1.0000710e+00]\n",
      " action shape: (7,)\n",
      " action: [ 0.03157094  0.00955625  0.29741952  0.03202063 -0.00409914  0.01140948\n",
      "  0.9999348 ]\n",
      " action shape: (7,)\n",
      " action: [0.05429591 0.06658683 0.4120644  0.05080922 0.00398371 0.03248014\n",
      " 1.000114  ]\n",
      " action shape: (7,)\n",
      " action: [0.02413148 0.06882215 0.4644511  0.0604142  0.04271334 0.02525135\n",
      " 0.9998252 ]\n",
      " action shape: (7,)\n",
      "{'Return': 1.0, 'Horizon': 53, 'Success_Rate': 1.0}\n"
     ]
    }
   ],
   "source": [
    "stats = rollout(\n",
    "    policy=policy, \n",
    "    env=env, \n",
    "    horizon=rollout_horizon, \n",
    "    render=False, \n",
    "    video_writer=video_writer, \n",
    "    video_skip=5, \n",
    "    camera_names=[\"agentview\"]\n",
    ")\n",
    "print(stats)\n",
    "video_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79bc19",
   "metadata": {},
   "source": [
    "### Visualize the rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97472b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"rollout_lift.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
